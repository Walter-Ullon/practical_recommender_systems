{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "580bcca8-771e-489c-94e2-1d74236290ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "import pickle\n",
    "import logging\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from decimal import Decimal\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "import math\n",
    "from datetime import datetime\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655ca4e8-eb94-4aa3-b7d2-53224665a849",
   "metadata": {},
   "source": [
    "---\n",
    "### About this notebook:\n",
    "In this chapter we begin looking at Funk Singular Value Decomposition to detect latent features and provide recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2e8415-fd88-4dd6-8d2b-d20ecfa761dc",
   "metadata": {},
   "source": [
    "---\n",
    "### Load Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec783903-9d9e-46b9-a552-7865e317b0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_timestamp</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>517025</td>\n",
       "      <td>40679</td>\n",
       "      <td>3890160</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2017-09-12 22:20:49-04</td>\n",
       "      <td>explicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>517026</td>\n",
       "      <td>40679</td>\n",
       "      <td>4034228</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2017-02-17 01:00:48-05</td>\n",
       "      <td>explicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>517027</td>\n",
       "      <td>40679</td>\n",
       "      <td>4540710</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2017-03-29 09:37:45-04</td>\n",
       "      <td>explicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>517028</td>\n",
       "      <td>40679</td>\n",
       "      <td>4550098</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2017-02-17 02:50:43-05</td>\n",
       "      <td>explicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>517029</td>\n",
       "      <td>40679</td>\n",
       "      <td>4633694</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2019-02-25 14:01:52-05</td>\n",
       "      <td>explicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921888</th>\n",
       "      <td>517020</td>\n",
       "      <td>40679</td>\n",
       "      <td>2568862</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2017-07-22 22:10:16-04</td>\n",
       "      <td>explicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921889</th>\n",
       "      <td>517021</td>\n",
       "      <td>40679</td>\n",
       "      <td>2582496</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2017-06-11 16:36:48-04</td>\n",
       "      <td>explicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921890</th>\n",
       "      <td>517022</td>\n",
       "      <td>40679</td>\n",
       "      <td>3460252</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2016-02-01 13:07:21-05</td>\n",
       "      <td>explicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921891</th>\n",
       "      <td>517023</td>\n",
       "      <td>40679</td>\n",
       "      <td>3631112</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2017-01-08 12:59:39-05</td>\n",
       "      <td>explicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921892</th>\n",
       "      <td>517024</td>\n",
       "      <td>40679</td>\n",
       "      <td>3741834</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2017-04-12 05:09:59-04</td>\n",
       "      <td>explicit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>921893 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  user_id  movie_id  rating        rating_timestamp      type\n",
       "0       517025    40679   3890160    10.0  2017-09-12 22:20:49-04  explicit\n",
       "1       517026    40679   4034228     8.0  2017-02-17 01:00:48-05  explicit\n",
       "2       517027    40679   4540710     8.0  2017-03-29 09:37:45-04  explicit\n",
       "3       517028    40679   4550098     8.0  2017-02-17 02:50:43-05  explicit\n",
       "4       517029    40679   4633694     7.0  2019-02-25 14:01:52-05  explicit\n",
       "...        ...      ...       ...     ...                     ...       ...\n",
       "921888  517020    40679   2568862     7.0  2017-07-22 22:10:16-04  explicit\n",
       "921889  517021    40679   2582496    10.0  2017-06-11 16:36:48-04  explicit\n",
       "921890  517022    40679   3460252     9.0  2016-02-01 13:07:21-05  explicit\n",
       "921891  517023    40679   3631112     8.0  2017-01-08 12:59:39-05  explicit\n",
       "921892  517024    40679   3741834    10.0  2017-04-12 05:09:59-04  explicit\n",
       "\n",
       "[921893 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load a small sample:\n",
    "# ratings_df = pd.read_csv('data/user_ratings.csv', nrows = 10_000)\n",
    "ratings_df = pd.read_csv('data/user_ratings.csv')\n",
    "ratings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aff8775-29a2-44bd-8533-793184fc37a0",
   "metadata": {},
   "source": [
    "---\n",
    "### Define MatrixFactorization Class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f18095fb-ef98-4b35-90f2-fa77c8007e2c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ensure_dir(file_path):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "\n",
    "class MatrixFactorization(object):\n",
    "\n",
    "    Regularization = Decimal(0.002)\n",
    "    BiasLearnRate = Decimal(0.005)\n",
    "    BiasReg = Decimal(0.002)\n",
    "\n",
    "    LearnRate = Decimal(0.002)\n",
    "    all_movies_mean = 0\n",
    "    number_of_ratings = 0\n",
    "\n",
    "    item_bias = None\n",
    "    user_bias = None\n",
    "    beta = 0.02\n",
    "\n",
    "    iterations = 0\n",
    "\n",
    "    def __init__(self, save_path, max_iterations=10):\n",
    "        self.logger = logging.getLogger('funkSVD')\n",
    "        self.save_path = save_path\n",
    "        self.user_factors = None\n",
    "        self.item_factors = None\n",
    "        self.item_counts = None\n",
    "        self.item_sum = None\n",
    "        self.u_inx = None\n",
    "        self.i_inx = None\n",
    "        self.user_ids = None\n",
    "        self.movie_ids = None\n",
    "\n",
    "        self.all_movies_mean = 0.0\n",
    "        self.number_of_ratings = 0\n",
    "        self.MAX_ITERATIONS = max_iterations\n",
    "        random.seed(42)\n",
    "\n",
    "        ensure_dir(save_path)\n",
    "\n",
    "    def initialize_factors(self, ratings, k=25):\n",
    "        self.user_ids = set(ratings['user_id'].values)\n",
    "        self.movie_ids = set(ratings['movie_id'].values)\n",
    "        self.item_counts = ratings[['movie_id', 'rating']].groupby('movie_id').count()\n",
    "        self.item_counts = self.item_counts.reset_index()\n",
    "\n",
    "        self.item_sum = ratings[['movie_id', 'rating']].groupby('movie_id').sum()\n",
    "        self.item_sum = self.item_sum.reset_index()\n",
    "\n",
    "        self.u_inx = {r: i for i, r in enumerate(self.user_ids)}\n",
    "        self.i_inx = {r: i for i, r in enumerate(self.movie_ids)}\n",
    "\n",
    "        self.item_factors = np.full((len(self.i_inx), k), Decimal(0.1))\n",
    "        self.user_factors = np.full((len(self.u_inx), k), Decimal(0.1))\n",
    "\n",
    "        self.all_movies_mean = calculate_all_movies_mean(ratings)\n",
    "        self.logger.info(\"user_factors are {}\".format(self.user_factors.shape))\n",
    "        self.user_bias = defaultdict(lambda: 0)\n",
    "        self.item_bias = defaultdict(lambda: 0)\n",
    "\n",
    "    def predict(self, user, item):\n",
    "\n",
    "        pq = np.dot(self.item_factors[item], self.user_factors[user].T)\n",
    "        b_ui = self.all_movies_mean + self.user_bias[user] + self.item_bias[item]\n",
    "        prediction = b_ui + pq\n",
    "\n",
    "        if prediction > 10:\n",
    "            prediction = 10\n",
    "        elif prediction < 1:\n",
    "            prediction = 10\n",
    "        return prediction\n",
    "\n",
    "    def build(self, ratings, params):\n",
    "\n",
    "        if params:\n",
    "            k = params['k']\n",
    "            self.save_path = params['save_path']\n",
    "\n",
    "        self.train(ratings, k)\n",
    "\n",
    "    def split_data(self, min_rank, ratings):\n",
    "\n",
    "        users = self.user_ids\n",
    "\n",
    "        train_data_len = int((len(users) * 70 / 100))\n",
    "        test_users = set(random.sample(users, (len(users) - train_data_len)))\n",
    "        train_users = users - test_users\n",
    "\n",
    "        train = ratings[ratings['user_id'].isin(train_users)]\n",
    "        test_temp = ratings[ratings['user_id'].isin(test_users)].sort_values('rating_timestamp', ascending=False)\n",
    "        test = test_temp.groupby('user_id').head(min_rank)\n",
    "        additional_training_data = test_temp[~test_temp.index.isin(test.index)]\n",
    "\n",
    "        train = train.append(additional_training_data)\n",
    "\n",
    "        return test, train\n",
    "\n",
    "    def meta_parameter_train(self, ratings_df):\n",
    "\n",
    "        for k in [15, 20, 30, 40, 50, 75, 100]:\n",
    "            self.initialize_factors(ratings_df, k)\n",
    "            self.logger.info(\"Training model with {} factors\".format(k))\n",
    "            self.log(str(k), \"factor, iterations, train_mse, test_mse, time\")\n",
    "\n",
    "            test_data, train_data = self.split_data(10,\n",
    "                                                    ratings_df)\n",
    "            columns = ['user_id', 'movie_id', 'rating']\n",
    "            ratings = train_data[columns].as_matrix()\n",
    "            test = test_data[columns].as_matrix()\n",
    "\n",
    "            self.MAX_ITERATIONS = 10\n",
    "            iterations = 0\n",
    "            index_randomized = random.sample(range(0, len(ratings)), (len(ratings) - 1))\n",
    "\n",
    "            for factor in range(k):\n",
    "                factor_iteration = 0\n",
    "                factor_time = datetime.now()\n",
    "\n",
    "                last_err = sys.maxsize\n",
    "                last_test_mse = sys.maxsize\n",
    "                finished = False\n",
    "\n",
    "                while not finished:\n",
    "                    train_mse = self.stocastic_gradient_descent(factor,\n",
    "                                                                index_randomized,\n",
    "                                                                ratings)\n",
    "\n",
    "                    iterations += 1\n",
    "                    test_mse = self.calculate_rmse(test, factor)\n",
    "\n",
    "                    finished = self.finished(factor_iteration,\n",
    "                                             last_err,\n",
    "                                             train_mse,\n",
    "                                             last_test_mse,\n",
    "                                             test_mse)\n",
    "\n",
    "                    last_err = train_mse\n",
    "                    last_test_mse = test_mse\n",
    "                    factor_iteration += 1\n",
    "\n",
    "                    self.log(str(k), f\"{factor}, {iterations}, {train_mse}, {test_mse}, {datetime.now() - factor_time}\")\n",
    "\n",
    "            self.save(k, False)\n",
    "\n",
    "    def calculate_rmse(self, ratings, factor):\n",
    "\n",
    "        def difference(row):\n",
    "            user = self.u_inx[row[0]]\n",
    "            item = self.i_inx[row[1]]\n",
    "\n",
    "            pq = np.dot(self.item_factors[item][:factor + 1], self.user_factors[user][:factor + 1].T)\n",
    "            b_ui = self.all_movies_mean + self.user_bias[user] + self.item_bias[item]\n",
    "            prediction = b_ui + pq\n",
    "            MSE = (prediction - Decimal(row[2])) ** 2\n",
    "            return MSE\n",
    "\n",
    "        squared = np.apply_along_axis(difference, 1, ratings).sum()\n",
    "        return math.sqrt(squared / ratings.shape[0])\n",
    "\n",
    "    def train(self, ratings_df, k=40):\n",
    "\n",
    "        self.initialize_factors(ratings_df, k)\n",
    "        self.logger.info(\"training matrix factorization at {}\".format(datetime.now()))\n",
    "\n",
    "        ratings = ratings_df[['user_id', 'movie_id', 'rating']].to_numpy()\n",
    "\n",
    "        index_randomized = random.sample(range(0, len(ratings)), (len(ratings) - 1))\n",
    "\n",
    "        for factor in range(k):\n",
    "            factor_time = datetime.now()\n",
    "            iterations = 0\n",
    "            last_err = sys.maxsize\n",
    "            iteration_err = sys.maxsize\n",
    "            finished = False\n",
    "\n",
    "            while not finished:\n",
    "                start_time = datetime.now()\n",
    "                iteration_err = self.stocastic_gradient_descent(factor,\n",
    "                                                              index_randomized,\n",
    "                                                              ratings)\n",
    "\n",
    "\n",
    "                iterations += 1\n",
    "                self.logger.info(\"epoch in {}, f={}, i={} err={}\".format(datetime.now() - start_time,\n",
    "                                                                       factor,\n",
    "                                                                       iterations,\n",
    "                                                                       iteration_err))\n",
    "                finished = self.finished(iterations,\n",
    "                                         last_err,\n",
    "                                         iteration_err)\n",
    "                last_err = iteration_err\n",
    "            self.save(factor, finished)\n",
    "            self.logger.info(\"finished factor {} on f={} i={} err={}\".format(factor,\n",
    "                                                                  datetime.now() - factor_time,\n",
    "                                                                  iterations,\n",
    "                                                                  iteration_err))\n",
    "\n",
    "    def stocastic_gradient_descent(self, factor, index_randomized, ratings):\n",
    "\n",
    "        lr = self.LearnRate\n",
    "        b_lr = self.BiasLearnRate\n",
    "        r = self.Regularization\n",
    "        bias_r = self.BiasReg\n",
    "\n",
    "        for inx in index_randomized:\n",
    "            rating_row = ratings[inx]\n",
    "\n",
    "            u = self.u_inx[rating_row[0]]\n",
    "            i = self.i_inx[rating_row[1]]\n",
    "            rating = Decimal(rating_row[2])\n",
    "\n",
    "            err = (rating - self.predict(u, i))\n",
    "\n",
    "            self.user_bias[u] += b_lr * (err - bias_r * self.user_bias[u])\n",
    "            self.item_bias[i] += b_lr * (err - bias_r * self.item_bias[i])\n",
    "\n",
    "            user_fac = self.user_factors[u][factor]\n",
    "            item_fac = self.item_factors[i][factor]\n",
    "\n",
    "            self.user_factors[u][factor] += lr * (err * item_fac\n",
    "                                                  - r * user_fac)\n",
    "            self.item_factors[i][factor] += lr * (err * user_fac\n",
    "                                                  - r * item_fac)\n",
    "        return self.calculate_rmse(ratings, factor)\n",
    "\n",
    "    def finished(self, iterations, last_err, current_err,\n",
    "                 last_test_mse=0.0, test_mse=0.0):\n",
    "\n",
    "        if last_test_mse < test_mse or iterations >= self.MAX_ITERATIONS or last_err - current_err < 0.01:\n",
    "            self.logger.info('Finish w iterations: {}, last_err: {}, current_err {}, lst_rmse {}, rmse {}'\n",
    "                             .format(iterations, last_err, current_err, last_test_mse, test_mse))\n",
    "            return True\n",
    "        else:\n",
    "            self.iterations += 1\n",
    "            return False\n",
    "\n",
    "    def save(self, factor, finished):\n",
    "\n",
    "        save_path = self.save_path + '/model/'\n",
    "        if not finished:\n",
    "            save_path += str(factor) + '/'\n",
    "\n",
    "        ensure_dir(save_path)\n",
    "\n",
    "        self.logger.info(\"saving factors in {}\".format(save_path))\n",
    "        user_bias = {uid: self.user_bias[self.u_inx[uid]] for uid in self.u_inx.keys()}\n",
    "        item_bias = {iid: self.item_bias[self.i_inx[iid]] for iid in self.i_inx.keys()}\n",
    "\n",
    "        uf = pd.DataFrame(self.user_factors,\n",
    "                          index=self.user_ids)\n",
    "        it_f = pd.DataFrame(self.item_factors,\n",
    "                            index=self.movie_ids)\n",
    "\n",
    "        with open(save_path + 'user_factors.json', 'w') as outfile:\n",
    "            outfile.write(uf.to_json())\n",
    "        with open(save_path + 'item_factors.json', 'w') as outfile:\n",
    "            outfile.write(it_f.to_json())\n",
    "        with open(save_path + 'user_bias.data', 'wb') as ub_file:\n",
    "            pickle.dump(user_bias, ub_file)\n",
    "        with open(save_path + 'item_bias.data', 'wb') as ub_file:\n",
    "            pickle.dump(item_bias, ub_file)\n",
    "\n",
    "    def log(self, filename, logtext):\n",
    "        path = self.save_path + '/meta/' + filename + '.csv'\n",
    "        ensure_dir(path)\n",
    "\n",
    "        with open(path, 'a') as log_file:\n",
    "            log_file.write(logtext + '\\n')\n",
    "\n",
    "\n",
    "def load_all_ratings(min_ratings):\n",
    "    columns = ['user_id', 'movie_id', 'rating', 'type', 'rating_timestamp']\n",
    "\n",
    "    ratings = pd.read_csv('data/user_ratings.csv')\n",
    "\n",
    "    user_count = ratings[['user_id', 'movie_id']].groupby('user_id').count()\n",
    "    user_count = user_count.reset_index()\n",
    "    user_ids = user_count[user_count['movie_id'] > min_ratings]['user_id']\n",
    "    ratings = ratings[ratings['user_id'].isin(user_ids)]\n",
    "\n",
    "    ratings['rating'] = ratings['rating'].astype(float)\n",
    "    return ratings\n",
    "\n",
    "\n",
    "def calculate_all_movies_mean(ratings):\n",
    "    avg = ratings['rating'].sum() / ratings.shape[0]\n",
    "    return Decimal(avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d80d3c-f98e-46a6-a3aa-156ca2055f2e",
   "metadata": {},
   "source": [
    "---\n",
    "### Create a MatrixFactorization object and run it -- Trains a Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12fd3398-5582-4d4b-940f-86ad5b4b75c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # log it:\n",
    "# logger = logging.getLogger('funkSVD')\n",
    "# logger.info(\"[BEGIN] Calculating matrix factorization\")\n",
    "\n",
    "# # instanstiate object and\n",
    "# MF = MatrixFactorization(save_path='./models/funkSVD/{}/'.format(datetime.now()), max_iterations=40)\n",
    "# loaded_ratings = load_all_ratings(min_ratings=20)\n",
    "# logger.info(\"using {} ratings\".format(loaded_ratings.shape[0]))\n",
    "\n",
    "# # train the model:\n",
    "# MF.train(loaded_ratings, k=20)\n",
    "# logger.info(\"[DONE] Calculating matrix factorization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427ed188-7c45-4adf-92b7-5f304d113a41",
   "metadata": {},
   "source": [
    "---\n",
    "### Define Prediction/Recommendation Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f769823-85e7-4d4c-8eef-ca3418984941",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load model dictionaries:\n",
    "def load_model(save_path):\n",
    "    with open(save_path + 'user_bias.data', 'rb') as ub_file:\n",
    "        user_bias = pickle.load(ub_file)\n",
    "    with open(save_path + 'item_bias.data', 'rb') as ub_file:\n",
    "        item_bias = pickle.load(ub_file)\n",
    "    with open(save_path + 'user_factors.json', 'r') as infile:\n",
    "        user_factors = pd.DataFrame(json.load(infile)).T\n",
    "    with open(save_path + 'item_factors.json', 'r') as infile:\n",
    "        item_factors = pd.DataFrame(json.load(infile)).T\n",
    "\n",
    "    # return dictionaries:\n",
    "    return user_bias, item_bias, user_factors, item_factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926aea66-639e-4305-b079-972dce59caa1",
   "metadata": {},
   "source": [
    "#### Predict Score for user-item:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34caa237-703d-4924-bdf4-c5501a6efa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict rating for given usee and item:\n",
    "def predict_score(ratings_df, user_id, item_id, model_path):\n",
    "    # load saved dicts:\n",
    "    user_bias_dict, item_bias_dict, user_factors_dict, item_factors_dict = load_model(model_path)\n",
    "    \n",
    "    # select user and item keys from respective dicts:\n",
    "    user_bias = float(user_bias_dict[user_id])\n",
    "    item_bias = float(item_bias_dict[item_id])\n",
    "    user_factors = user_factors_dict[str(user_id)]\n",
    "    item_factors = item_factors_dict[str(item_id)]\n",
    "    \n",
    "    # obtain global avg:\n",
    "    global_avg = ratings_df['rating'].sum() / ratings_df['rating'].shape[0]\n",
    "    \n",
    "    # calculate rating:\n",
    "    predicted_rating = np.round(global_avg + user_bias + item_bias + np.dot(item_factors, user_factors), 2)\n",
    "    \n",
    "    return predicted_rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e11412f-6e32-49cc-b4b4-a656cb8c4565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_score(ratings_df, 40679, 2582496, 'models/funkSVD/2022-05-18 18:47:33.835619/model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5457a8ca-48bc-4a14-94a4-cf9a0215b453",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
